{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArooshKics/PdfOcrCode/blob/master/PdfOcr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2NxD0hkOR0O",
        "outputId": "065145dc-1b1c-4deb-9893-94474f3f748f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import csv\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, Conv2D, MaxPooling2D, BatchNormalization, Activation, Reshape, Dense, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-6NTTdBBIaz"
      },
      "source": [
        "## Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPDjEBo5BIBj"
      },
      "outputs": [],
      "source": [
        "# Paths of images and text directories\n",
        "images_dir = '/content/drive/MyDrive/Pdf_Ocr/Datasets/Dataset_500/images'\n",
        "text_files_dir = '/content/drive/MyDrive/Pdf_Ocr/Datasets/Dataset_500/texts'\n",
        "char_maps_pth = '/content/drive/MyDrive/Pdf_Ocr/Datasets/Dataset_500/labels/gt_char.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6UARKrjBwSf"
      },
      "outputs": [],
      "source": [
        "gt_dir = char_maps_pth\n",
        "images_dir = images_dir\n",
        "\n",
        "gt = []\n",
        "filenames = []\n",
        "\n",
        "def _size_alright(directory, img_width=None, img_range=None):\n",
        "    if img_range == None:\n",
        "        return True\n",
        "\n",
        "    image = cv2.imread(directory, cv2.IMREAD_GRAYSCALE)\n",
        "    if image.shape[1] <= img_width + img_range and image.shape[1] >= img_width - img_range:\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "# Read by gt by reading the csv path file in directory\n",
        "with open(gt_dir, 'r', encoding='utf8') as gt_file:\n",
        "    text = csv.reader(gt_file, quoting=csv.QUOTE_NONE)\n",
        "    # print(\"Reading the gt file : \") # Debug print statement by Aroosh\n",
        "    for i, row in enumerate(text):\n",
        "        # print(f\"Reading row {i} : {row}\") # Debug print statement by Aroosh\n",
        "        if images_dir is None:\n",
        "            is_row_valid = True\n",
        "        else:\n",
        "            image_name = row[0].split('.')[0]\n",
        "            path = os.path.join(images_dir, image_name+\".jpg\")\n",
        "            if os.path.exists(path):\n",
        "              image = cv2.imread(path)\n",
        "              img_wdth = image.shape[1]\n",
        "              is_row_valid = path is not None and _size_alright(path, img_wdth, img_range = None)\n",
        "              if is_row_valid:\n",
        "                sub_row = row[1:]\n",
        "                sub_row[0]  = sub_row[0].replace(\"[\",'')\n",
        "                sub_row[0]  = sub_row[0].replace('\"','')\n",
        "                sub_row[-1] = sub_row[-1].replace(\"]\",'')\n",
        "                sub_row[-1] = sub_row[-1].replace('\"','')\n",
        "\n",
        "                #------------Lines added by Aroosh-------------#\n",
        "                # Added on 26 March 2024\n",
        "                # Issue : 1. last entry has ] which is replaced above, but here we get last entry as '' to make equal sequence\n",
        "                # 2. cannot convert '' to int and also 14] to int.\n",
        "                sub_row = [num.replace(\"]\",'') for num in sub_row]\n",
        "                sub_row = [num for num in sub_row if num != '']\n",
        "                #------------Lines added by Aroosh-------------#\n",
        "\n",
        "                gt.append([int(num) for num in sub_row])\n",
        "\n",
        "                if images_dir is not None:\n",
        "                  filenames.append(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "astptSyeHFyc",
        "outputId": "d21828ff-84c7-407f-de1f-16ef473e417a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "460 460\n"
          ]
        }
      ],
      "source": [
        "print(len(gt), len(filenames))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "O_Bi1hOjobbJ",
        "outputId": "c8d3fb8f-dbac-4691-812d-f2176e22d85a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Pdf_Ocr/Datasets/Dataset_500/images/Al Jihad Fil Islam (Volume 02) SwaneUmri Hazrat Uma103_Line4.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "filenames[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI0YVuEIHwmQ"
      },
      "source": [
        "## Loading Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "So3vOviqHy_P"
      },
      "outputs": [],
      "source": [
        "images = [] # images will be a list of images\n",
        "\n",
        "for img_pth in filenames:\n",
        "    img = cv2.imread(img_pth)\n",
        "    if img is not None:\n",
        "      images.append(img)\n",
        "    else:\n",
        "      print(f\"Failed to load image: {img_pth}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSbVUmLrzfjC",
        "outputId": "5140968e-47c5-40d5-ebfc-1c191aacf81e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(93, 1500, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def is_light_or_dark(rgb_color):\n",
        "    r, g, b = rgb_color\n",
        "    hsp = math.sqrt(0.299 * (r * r) + 0.587 * (g * g) + 0.114 * (b * b))\n",
        "    if hsp > 150:  # Threshold for light/dark\n",
        "        return 'light'\n",
        "    else:\n",
        "        return 'dark'\n",
        "\n",
        "def get_gray_image(image):\n",
        "    # Function to invert image if background is dark\n",
        "    def invert_image(img):\n",
        "        return cv2.bitwise_not(img)\n",
        "\n",
        "    # Check if the image has a dark background\n",
        "    def has_dark_background(img):\n",
        "        average_color = np.mean(img, axis=(0, 1))\n",
        "        return is_light_or_dark(average_color) == 'dark'\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # If background is dark, invert the grayscale image\n",
        "    if has_dark_background(image):\n",
        "        gray_image = invert_image(gray_image)\n",
        "\n",
        "    return gray_image"
      ],
      "metadata": {
        "id": "fVdtTSU46eqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lucVJ5vQvBy"
      },
      "outputs": [],
      "source": [
        "features = [] # append the f , feature in it\n",
        "seq_len = [] # append the new_size[0] i.e. the height here\n",
        "\n",
        "num_buckets = 4\n",
        "image_size = [\"None\", 64]\n",
        "\n",
        "for image in images:\n",
        "\n",
        "  \"\"\"\n",
        "    First the image is binarized then other things happen here.\n",
        "  \"\"\"\n",
        "\n",
        "  # Convert to grayscale\n",
        "  image = get_gray_image(image)\n",
        "\n",
        "  (wt, ht) = image_size\n",
        "\n",
        "\n",
        "  (h, w) = image.shape\n",
        "  # If Image  width is not defiend in our case wt is always none because the in config file none,64\n",
        "  f = ht / h\n",
        "  new_size = (int(w * f), ht)\n",
        "\n",
        "  # # resize the image into new size\n",
        "  image = cv2.resize(image, new_size)\n",
        "\n",
        "  features.append(image)\n",
        "  seq_len.append(new_size[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8sfF_gfRrfk",
        "outputId": "ac3e5d61-1e49-4ab3-9ac5-d729dce5ff4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(711, 4000, 460)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "min(seq_len), max(seq_len), len(seq_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3NRoUSVuxrc"
      },
      "source": [
        "# Bucket Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hD3CEYZJRakc"
      },
      "outputs": [],
      "source": [
        "def _bucket(images, seq_len, num_buckets):\n",
        "    # Bucketing may require some experimentation for each dataset. If there are too many buckets and too few points\n",
        "    # then some buckets may be empty because the total range is divided *equally* between all buckets. Empty buckets\n",
        "    # may cause errors in later functions.\n",
        "    # This function does not remove empty buckets deliberately, because otherwise the user may think that the data is\n",
        "    # being divided into the number of buckets specified, which may then lead to reporting errors.\n",
        "\n",
        "    min_seq_len = min(seq_len)\n",
        "    max_seq_len = max(seq_len)\n",
        "    bins = np.arange(min_seq_len, max_seq_len, (max_seq_len - min_seq_len) / num_buckets)\n",
        "    bucket_indices = np.digitize(seq_len, bins)  # should be a list of values ranging from 1 to num_buckets inclusively\n",
        "\n",
        "    # This does bucketing in O(N) where N is the number of images, i.e.\n",
        "    # we only have to traverse the bucket_indices list of size N once.\n",
        "    bucket_images = [[] for _ in range(num_buckets)]\n",
        "    bucket_seq_len = [[] for _ in range(num_buckets)]\n",
        "\n",
        "    for i, j in enumerate(bucket_indices):\n",
        "        bucket_images[j - 1].append(images[i])\n",
        "        bucket_seq_len[j - 1].append(np.array(seq_len[i]))\n",
        "\n",
        "    for i in range(num_buckets):\n",
        "        bucket_seq_len[i] = np.array(bucket_seq_len[i])\n",
        "\n",
        "    return bucket_images, bucket_seq_len, bucket_indices\n",
        "\n",
        "features, seq_len, bucket_indices = _bucket(features, seq_len, num_buckets)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(seq_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PSM7Umn3kMT",
        "outputId": "4dcbc67e-1960-464b-b5aa-509f69b1f3c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _pad_image_horizontally(image, max_width, flip_image=True):\n",
        "    image = _copy_to_target(image, [image.shape[0], max_width], flip_image=flip_image)\n",
        "    image = _normalize(image)\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "mUdgH1eT7ssI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8Hov2JitHTd"
      },
      "outputs": [],
      "source": [
        "resized_features = []\n",
        "\n",
        "if image_size[0] is None:\n",
        "    for features_bucket, seq_len_bucket in zip(features, seq_len):\n",
        "        new_features = []\n",
        "        # below we get a [] for seq_len_bucket which causes an issue\n",
        "        max_seq_len = max([i for i in seq_len_bucket])\n",
        "        for f in features_bucket:\n",
        "            # Pad hosrizontally always because we have veritically standard 64 mention in config_file\n",
        "            n_f = _pad_image_horizontally(f, max_seq_len, flip_image=flip_image)\n",
        "            new_features.append(n_f)\n",
        "\n",
        "            if VERBOSE:\n",
        "                cv2.imshow(\"padded image\", n_f)\n",
        "                cv2.waitKey(1000)\n",
        "        # resize image according to the new features\n",
        "        resized_features.append(np.array(new_features))\n",
        "\n",
        "features = resized_features\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = seq_len[0] # have to see later what caused this , to have the element at index 0"
      ],
      "metadata": {
        "id": "_YaMjyEK4k0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZ7Rv5WEvNLb"
      },
      "outputs": [],
      "source": [
        "features = np.array(features)\n",
        "seq_len =  np.array(seq_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUQa2gV2u1mP"
      },
      "source": [
        "# Bucket Ground Truths"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(gt), len(gt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffeu0CiX4SIf",
        "outputId": "f2718cf4-be09-4cda-a198-ca48c4b4eef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, 460)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_seq_len = [len(g) for g in gt]"
      ],
      "metadata": {
        "id": "j_2y9--e4adg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_seq_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdpMZ6Ad5gXf",
        "outputId": "fbbccfcc-c167-4600-aaf3-1d2cd5eca4c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "460"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = [gt]\n",
        "y_seq_len = [np.array(y_seq_len)]"
      ],
      "metadata": {
        "id": "z_r1hl275lvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(bucket_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvbyJmXG5reU",
        "outputId": "c458fdce-2aa1-4a77-d9ff-b068de19e823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "460"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _bucket_gt(gt, num_buckets, bucket_indices):\n",
        "    y_seq_len = [len(g) for g in gt]\n",
        "\n",
        "#Load the data w.r.t the bucket indices\n",
        "    if bucket_indices is None:\n",
        "        y = [gt]\n",
        "        y_seq_len = [np.array(y_seq_len)]\n",
        "\n",
        "    else:\n",
        "        y = [[] for _ in range(num_buckets)]\n",
        "        seq_len = [[] for _ in range(num_buckets)]\n",
        "\n",
        "        for i, j in enumerate(bucket_indices):\n",
        "            y[j-1].append(np.array(gt[i]))\n",
        "            seq_len[j-1].append(np.array(y_seq_len[i]))\n",
        "\n",
        "        for i in range(num_buckets):\n",
        "            y[i] = np.array(y[i])\n",
        "            seq_len[i] = np.array(seq_len[i])\n",
        "\n",
        "        y_seq_len = seq_len\n",
        "\n",
        "    return np.array(y), np.array(y_seq_len)"
      ],
      "metadata": {
        "id": "CkPEFw6V58py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we have the imges,their seq lens and same y and their seq lens\n",
        "# features = np.array(features)\n",
        "# seq_len =  np.array(seq_len)\n",
        "# y = [gt]\n",
        "# y_seq_len = [np.array(y_seq_len)]\n",
        "\n",
        "X = features\n",
        "X_seq_len = seq_len\n",
        "\n",
        "vocab_size = int(max([max(yij) for yi in y for yij in yi]) + 1)\n",
        "y_max_len = np.max([np.max(s) for s in y_seq_len])\n",
        "\n",
        "dataset = (X, X_seq_len, y, y_seq_len)"
      ],
      "metadata": {
        "id": "1XEW3xwq4saf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(dataset, r=1.0, shuffle=True, all_indices=None): #dataset => (x,x_seq_len,y,y_seq_len)\n",
        "    # Prepare 'dataset' for the minibatches function.\n",
        "    # Each element in 'dataset' is a list of size 'num_buckets'.\n",
        "\n",
        "    # If r != 1, then divide each bucket into two sets. Used to prepare test and validation\n",
        "    # sets. Dividing each bucket separately makes the validation set more balanced.\n",
        "\n",
        "    print(\"Preparing dataset....\")\n",
        "    restoring_previous = False if all_indices is None else True\n",
        "\n",
        "    num_buckets = dataset[0].shape[0]#No. of buckets\n",
        "    train_dataset = [[] for _ in range(num_buckets)]# train dataset initialization\n",
        "    val_dataset = [[] for _ in range(num_buckets)]# validation dataset initialization\n",
        "\n",
        "    to_remove = []\n",
        "    if not restoring_previous:# Restoring flag in config\n",
        "        all_indices = []\n",
        "    for i in range(num_buckets):\n",
        "        num_train = dataset[0][i].shape[0]\n",
        "\n",
        "        if restoring_previous:\n",
        "            indices = all_indices[i]\n",
        "        else:\n",
        "            indices = np.arange(num_train)\n",
        "            if shuffle:\n",
        "                np.random.shuffle(indices)#Suffle the indices\n",
        "            all_indices.append(indices)\n",
        "#Split the dataset into the validation and train dataset.\n",
        "        split_at = int(np.ceil(r*num_train))\n",
        "        indices_train = indices[:split_at]\n",
        "        indices_val = indices[split_at:]\n",
        "#And Make sure the validation data is not in train dataset and vise versa\n",
        "        train_dataset[i] = [d[i][indices_train] for d in dataset]\n",
        "        if split_at == num_train:\n",
        "            to_remove.append(i)\n",
        "        else:\n",
        "            val_dataset[i] = [d[i][indices_val] for d in dataset]\n",
        "#Create a empty buckets in val_dataset of training dataset.\n",
        "    val_dataset = [vd for i, vd in enumerate(val_dataset) if not i in to_remove] if r != 1 else []\n",
        "\n",
        "    return train_dataset, val_dataset, all_indices\n"
      ],
      "metadata": {
        "id": "iMweesiH8llP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SPLIT_RATIO = 0.80\n",
        "indices = None\n",
        "train_dataset,val_dataset, indices = prepare_dataset(dataset,\n",
        "                r=SPLIT_RATIO,\n",
        "                shuffle=True,\n",
        "                all_indices=indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWuKB1Rg6bqi",
        "outputId": "de8dc0ca-54b5-4693-a681-b8fa1c695a8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing dataset....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_dataset), train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWZ4EXtg7V1L",
        "outputId": "6729f45c-d169-4f33-abdf-1883675fbc3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, [])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zAw1jHN48hZz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "17p_Sb56knK2KvLefYljxYqCeSDte-mFO",
      "authorship_tag": "ABX9TyPZQYWgbFB/zVMelXr59Dnz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}