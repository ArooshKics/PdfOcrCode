{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN9BsIoellJwjun5U7+ta0Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArooshKics/PdfOcrCode/blob/master/PdfOcr_New.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rEbp_aeKbGX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26b41036-956b-49de-95e9-b2fd02341be6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive is already mounted.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import csv\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, Conv2D, MaxPooling2D, BatchNormalization, Activation, Reshape, Dense, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# Check if Google Drive is mounted\n",
        "if not os.path.exists('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "else:\n",
        "    print(\"Google Drive is already mounted.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths of images and text directories\n",
        "images_dir = '/content/drive/MyDrive/Pdf_Ocr/Datasets/Dataset_500/images'\n",
        "texts_dir = '/content/drive/MyDrive/Pdf_Ocr/Datasets/Dataset_500/texts'\n",
        "lt_pth = '/content/drive/MyDrive/Pdf_Ocr/Datasets/Dataset_500/labels/lt_char.csv'"
      ],
      "metadata": {
        "id": "3P5aI2JvKyjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Images and their corresponding text.\n",
        "\n",
        "img_pths= []\n",
        "txt_pths = []\n",
        "\n",
        "for img_name in os.listdir(images_dir):\n",
        "  img_pth = os.path.join(images_dir, img_name)\n",
        "  txt_pth = os.path.join(texts_dir, img_name[:-4]+\".txt\")\n",
        "\n",
        "  if os.path.exists(img_pth) and os.path.exists(txt_pth):\n",
        "    img_pths.append(img_pth)\n",
        "    txt_pths.append(txt_pth)\n"
      ],
      "metadata": {
        "id": "6yzzARjPOPx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(img_pths), len(txt_pths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujCXdQvGPjA5",
        "outputId": "4ad877f3-084d-40bf-be14-ae39d771576f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(460, 460)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import re\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    # # Read image\n",
        "    # image = tf.io.read_file(image_path)\n",
        "    # # Decode image\n",
        "    # image = tf.io.decode_image(image, channels=3)  # Assuming RGB images\n",
        "    # # Resize image if needed\n",
        "    # # image = tf.image.resize(image, [new_height, new_width])\n",
        "\n",
        "    image = cv2.imread(image_path)\n",
        "    new_size = (1000, 64) # width, height, channel\n",
        "    image = cv2.resize(image, new_size)\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "# Preprocess Text file\n",
        "\n",
        "def preprocess_text(txt_pth):\n",
        "    english_chars = '[A-Za-z0-9۱۲۳۴۵۶۷۸۹۰]'\n",
        "\n",
        "    with open(txt_pth, mode='r', encoding='utf-8-sig') as f:\n",
        "        try:\n",
        "            text = f.read()\n",
        "\n",
        "            non_joiners = ['آ', 'ا', 'د', 'ڈ', 'ذ', 'ر', 'ڑ', 'ز', 'ژ', 'ں', 'و', 'ے', '\\\"', '،', '(', ')', '؟', '۔', '!', ':']\n",
        "            ligatures = []\n",
        "            ligatures_return = []\n",
        "\n",
        "            words = text.split(' ')\n",
        "\n",
        "            for word in words:\n",
        "                ligature = ''\n",
        "                for char in word:\n",
        "                    if char not in non_joiners:\n",
        "                        ligature += char\n",
        "                    else:\n",
        "                        ligature += char\n",
        "                        ligatures.append(ligature)\n",
        "                        ligatures_return.append(ligature)\n",
        "                        ligature = ''\n",
        "                if ligature!= '':\n",
        "                    ligatures.append(ligature)\n",
        "                    ligatures_return.append(ligature)\n",
        "\n",
        "            extra_char = ['\\\"', '،', '(', ')', '؟', '۔', '!', ':', 'ء']\n",
        "\n",
        "            lig_list = []\n",
        "            for ligature in ligatures:\n",
        "                for char in ligature:\n",
        "                    result = re.findall(english_chars, char)\n",
        "                    if result:\n",
        "                        lig_list.append(char + '_isolated')\n",
        "                        ligature = ligature.replace(char, '')\n",
        "                    if char in extra_char:\n",
        "                        char_index = ligature.index(char)\n",
        "                        ligature = ligature.replace(char, '')\n",
        "                if ligature:\n",
        "                    if (len(ligature) == 1):\n",
        "                        a = ligature + '_isolated'\n",
        "                        lig_list.append(a)\n",
        "                    else:\n",
        "                        initial = ligature[0]\n",
        "                        b = initial + '_initial'\n",
        "                        lig_list.append(b)\n",
        "                        middles = ligature[1:-1]\n",
        "                        if middles:\n",
        "                            for middle in middles:\n",
        "                                c = middle + '_middle'\n",
        "                                lig_list.append(c)\n",
        "                        final = ligature[-1]\n",
        "                        d = final + '_final'\n",
        "                        lig_list.append(d)\n",
        "\n",
        "            # Load the label dictionary from the CSV file\n",
        "            with open(lt_pth, mode='r') as lt_file:\n",
        "                reader = csv.reader(lt_file)\n",
        "                label_dict = {row[0]: int(row[1]) for row in reader}\n",
        "\n",
        "            # Convert the ligatures to labels\n",
        "            labels = [label_dict.get(lig, 0) for lig in lig_list]\n",
        "\n",
        "            return labels\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"Exception occured\")\n",
        "            print(e)\n",
        "            return []\n",
        "\n"
      ],
      "metadata": {
        "id": "4K23QqxhMgAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "labels = []\n",
        "\n",
        "for img_pth, txt_pth in zip(img_pths,txt_pths):\n",
        "  image = preprocess_image(img_pth)\n",
        "  images.append(image)\n",
        "\n",
        "  label = preprocess_text(txt_pth)\n",
        "  labels.append(label)\n"
      ],
      "metadata": {
        "id": "AjyxeYs1gQJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_lists(labels):\n",
        "    max_length = max(len(lst) for lst in labels)\n",
        "    padded_lists = [lst + [-1] * (max_length - len(lst)) for lst in labels]\n",
        "    return padded_lists, max_length\n",
        "\n",
        "padded_labels, max_length = pad_lists(labels)"
      ],
      "metadata": {
        "id": "1E8ebo9OqoIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels[1]), len(padded_labels[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMMlHtIZrHmc",
        "outputId": "cb4ba0fe-b55b-42c6-e018-036a613aa81d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46, 79)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert image lists to TensorFlow tensors\n",
        "images_tensor = tf.convert_to_tensor(images)"
      ],
      "metadata": {
        "id": "sFdoMTB0rQii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert label lists to TensorFlow tensors\n",
        "labels_tensor = tf.convert_to_tensor(padded_labels)"
      ],
      "metadata": {
        "id": "NESWo9TsrYOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a TensorFlow dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((images_tensor, labels_tensor))\n",
        "\n",
        "# Shuffle and batch the dataset\n",
        "BATCH_SIZE = 5\n",
        "dataset = dataset.shuffle(buffer_size=len(images)).batch(BATCH_SIZE)\n",
        "\n",
        "# Example usage of the dataset\n",
        "for batch in dataset.take(2):\n",
        "    batch_images, batch_labels = batch\n",
        "    print(\"Batch of images shape:\", batch_images.shape)\n",
        "    print(\"Batch of labels shape:\", batch_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W23OTEmhArK",
        "outputId": "885a9c56-b282-4fc0-ff65-3b716abfd9de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch of images shape: (5, 64, 1000)\n",
            "Batch of labels shape: (5, 79)\n",
            "Batch of images shape: (5, 64, 1000)\n",
            "Batch of labels shape: (5, 79)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Tblz1CixenH",
        "outputId": "2dfc09cc-0be2-4d6b-ccb7-5b2486182124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for image, label in zip(batch_images, batch_labels):\n",
        "  print(image.shape, label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvbDpQuP6OjQ",
        "outputId": "faa1504f-8b21-4d91-aa34-d95628b7fda7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 1000) (79,)\n",
            "(64, 1000) (79,)\n",
            "(64, 1000) (79,)\n",
            "(64, 1000) (79,)\n",
            "(64, 1000) (79,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_labels[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnvGo5fJ-Ks9",
        "outputId": "1b0b0431-5a4b-4bee-92a4-8002e5470c3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(79,), dtype=int32, numpy=\n",
              "array([  7,  14,  15,  90,  31,  32,  27,  33,   1,  15,   3,   7,  19,\n",
              "        28,  34,  14, 132,  36,  51,  49,  27,  16,   3,  15,  16,  20,\n",
              "        66,  31,   5,  10,  14,   7,   8,   9,  10,   1,  12,  20,   5,\n",
              "         7,  72,  69,  42,  26,  27,  36,  14,  50,  21,  27,   7,  92,\n",
              "        37,   1,  15,  33,  34,  14,  10,  14,  26,   5,  17,  18,  14,\n",
              "        46,  64,  19,  21,  14,  33,  30,  -1,  -1,  -1,  -1,  -1,  -1,\n",
              "        -1], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LSTM, Bidirectional\n",
        "\n",
        "def build_crnn_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # CNN Layers\n",
        "    # CNN Layer 1\n",
        "    model.add(Conv2D(filters=32, kernel_size=(5, 5), strides=(1, 1), padding='SAME', activation='relu', input_shape=(64, 1000, 1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='SAME'))\n",
        "\n",
        "    # CNN Layer 2\n",
        "    model.add(Conv2D(filters=64, kernel_size=(5, 5), strides=(1, 2), padding='SAME', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding='SAME'))\n",
        "\n",
        "    # CNN Layer 3\n",
        "    model.add(Conv2D(filters=128, kernel_size=(5, 5), strides=(1, 2), padding='SAME', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding='SAME'))\n",
        "\n",
        "    # CNN Layer 4\n",
        "    model.add(Conv2D(filters=128, kernel_size=(5, 5), strides=(1, 2), padding='SAME', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding='SAME'))\n",
        "\n",
        "    # CNN Layer 5\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 2), padding='SAME', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding='SAME'))\n",
        "\n",
        "    # CNN Layer 6\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 2), padding='SAME', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding='SAME'))\n",
        "\n",
        "    # CNN Layer 7\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), padding='SAME', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(1, 1), strides=(1, 1), padding='SAME'))\n",
        "\n",
        "    # Flatten Layer\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Reshape Layer\n",
        "    model.add(Reshape((64, -1)))  # Reshape to (64, 1000)\n",
        "\n",
        "    # Bidirectional LSTM Layers\n",
        "    # Bidirectional LSTM Layer 1\n",
        "    model.add(Bidirectional(LSTM(units=512, return_sequences=True)))\n",
        "\n",
        "    # Bidirectional LSTM Layer 2\n",
        "    model.add(Bidirectional(LSTM(units=512, return_sequences=False)))\n",
        "\n",
        "    # Dropout Layer\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build the CRNN model\n",
        "crnn_model = build_crnn_model()\n",
        "\n",
        "# Print model summary\n",
        "crnn_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ-CiLwphICP",
        "outputId": "3e90fbf6-e5ad-49e8-cc5f-30ba051e6b06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_108 (Conv2D)         (None, 64, 1000, 32)      832       \n",
            "                                                                 \n",
            " max_pooling2d_104 (MaxPool  (None, 32, 500, 32)       0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " conv2d_109 (Conv2D)         (None, 32, 250, 64)       51264     \n",
            "                                                                 \n",
            " max_pooling2d_105 (MaxPool  (None, 32, 125, 64)       0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " conv2d_110 (Conv2D)         (None, 32, 63, 128)       204928    \n",
            "                                                                 \n",
            " max_pooling2d_106 (MaxPool  (None, 32, 32, 128)       0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " conv2d_111 (Conv2D)         (None, 32, 16, 128)       409728    \n",
            "                                                                 \n",
            " max_pooling2d_107 (MaxPool  (None, 32, 8, 128)        0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " conv2d_112 (Conv2D)         (None, 32, 4, 256)        295168    \n",
            "                                                                 \n",
            " max_pooling2d_108 (MaxPool  (None, 32, 2, 256)        0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " conv2d_113 (Conv2D)         (None, 32, 1, 256)        590080    \n",
            "                                                                 \n",
            " max_pooling2d_109 (MaxPool  (None, 32, 1, 256)        0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " conv2d_114 (Conv2D)         (None, 32, 1, 512)        1180160   \n",
            "                                                                 \n",
            " max_pooling2d_110 (MaxPool  (None, 32, 1, 512)        0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " flatten_14 (Flatten)        (None, 16384)             0         \n",
            "                                                                 \n",
            " reshape_2 (Reshape)         (None, 64, 256)           0         \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirecti  (None, 64, 1024)          3149824   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirecti  (None, 1024)              6295552   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 79)                80975     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12258511 (46.76 MB)\n",
            "Trainable params: 12258511 (46.76 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(lr=0.001)  # You can adjust the learning rate as needed\n",
        "crnn_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10  # Adjust the number of epochs as needed\n",
        "crnn_model.fit(dataset, epochs=num_epochs)\n",
        "\n",
        "# Optionally, you can evaluate the model on a test set\n",
        "# test_loss, test_acc = crnn_model.evaluate(test_images, test_labels)\n",
        "# print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-ClckY6iTCe",
        "outputId": "986b0a0c-77d5-4536-f145-c222919377d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "92/92 [==============================] - 14s 47ms/step - loss: 12259.4199 - accuracy: 0.0217\n",
            "Epoch 2/10\n",
            "92/92 [==============================] - 4s 46ms/step - loss: 21773.5195 - accuracy: 0.0304\n",
            "Epoch 3/10\n",
            "92/92 [==============================] - 4s 48ms/step - loss: 24241.5938 - accuracy: 0.0174\n",
            "Epoch 4/10\n",
            "92/92 [==============================] - 4s 47ms/step - loss: 32290.8984 - accuracy: 0.0217\n",
            "Epoch 5/10\n",
            "92/92 [==============================] - 4s 47ms/step - loss: 33809.3281 - accuracy: 0.0174\n",
            "Epoch 6/10\n",
            "92/92 [==============================] - 4s 48ms/step - loss: 41589.9453 - accuracy: 0.0217\n",
            "Epoch 7/10\n",
            "92/92 [==============================] - 4s 48ms/step - loss: 49640.4258 - accuracy: 0.0196\n",
            "Epoch 8/10\n",
            "92/92 [==============================] - 4s 49ms/step - loss: 56168.4570 - accuracy: 0.0217\n",
            "Epoch 9/10\n",
            "92/92 [==============================] - 4s 48ms/step - loss: 59180.7266 - accuracy: 0.0217\n",
            "Epoch 10/10\n",
            "92/92 [==============================] - 4s 47ms/step - loss: 68585.0938 - accuracy: 0.0217\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79a059598550>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path):\n",
        "    # Load the image in grayscale\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    # Resize the image to match the input shape of your model\n",
        "    image = cv2.resize(image, (1000, 64))\n",
        "    # Normalize the pixel values to be between 0 and 1\n",
        "    image = image / 255.0\n",
        "    # Add a batch dimension\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    # Add a channel dimension\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    return image\n",
        "\n",
        "def predict_image_label(model, image_path):\n",
        "    # Preprocess the image\n",
        "    image = preprocess_image(image_path)\n",
        "    # Make predictions\n",
        "    predictions = model.predict(image)\n",
        "    # Get the predicted label\n",
        "    predicted_label = np.argmax(predictions)\n",
        "    return predicted_label\n",
        "\n",
        "\n",
        "def predict_single_image(image_path):\n",
        "    # Load the trained model\n",
        "    model = crnn_model\n",
        "    # Predict the label of the image\n",
        "    predicted_label = predict_image_label(model, image_path)\n",
        "    return predicted_label\n",
        "\n",
        "image_path = \"/content/drive/MyDrive/Pdf_Ocr/Datasets/Dataset_500/images/Al Jihad Fil Islam (Volume 02) SwaneUmri Hazrat Uma100_Line19.jpg\"\n",
        "\n",
        "predicted_label = predict_single_image(image_path)\n",
        "print(\"Predicted label:\", predicted_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MCQN97c88eF",
        "outputId": "8ebf3795-f50e-4d98-888d-c100b0d12a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "Predicted label: 7\n"
          ]
        }
      ]
    }
  ]
}