{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArooshKics/PdfOcrCode/blob/master/PdfOcr_New.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rEbp_aeKbGX",
        "outputId": "19a8f868-4248-47a9-8b23-afc1329756e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import csv\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, Conv2D, MaxPooling2D, BatchNormalization, Activation, Reshape, Dense, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Check if Google Drive is mounted\n",
        "if not os.path.exists('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "else:\n",
        "    print(\"Google Drive is already mounted.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3P5aI2JvKyjK"
      },
      "outputs": [],
      "source": [
        "# Paths of images and text directories\n",
        "images_dir = '/content/drive/MyDrive/My Documents/Pdf_Ocr/Datasets/Training_200_set/images'\n",
        "texts_dir = '/content/drive/MyDrive/My Documents/Pdf_Ocr/Datasets/Training_200_set/texts'\n",
        "lt_pth = '/content/drive/MyDrive/My Documents/Pdf_Ocr/Datasets/Training_200_set/labels/lt_char.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6yzzARjPOPx8"
      },
      "outputs": [],
      "source": [
        "# Load Images and their corresponding text.\n",
        "\n",
        "img_pths= []\n",
        "txt_pths = []\n",
        "\n",
        "for img_name in os.listdir(images_dir):\n",
        "  img_pth = os.path.join(images_dir, img_name)\n",
        "  txt_pth = os.path.join(texts_dir, img_name[:-4]+\".txt\")\n",
        "\n",
        "  if os.path.exists(img_pth) and os.path.exists(txt_pth):\n",
        "    img_pths.append(img_pth)\n",
        "    txt_pths.append(txt_pth)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujCXdQvGPjA5",
        "outputId": "fdb9dd2e-417e-4f24-f0f6-be0156a79e5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "len(img_pths), len(txt_pths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4K23QqxhMgAR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import re\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    # # Read image\n",
        "    # image = tf.io.read_file(image_path)\n",
        "    # # Decode image\n",
        "    # image = tf.io.decode_image(image, channels=3)  # Assuming RGB images\n",
        "    # # Resize image if needed\n",
        "    # # image = tf.image.resize(image, [new_height, new_width])\n",
        "\n",
        "    image = cv2.imread(image_path)\n",
        "    new_size = (1000, 64) # width, height, channel\n",
        "    image = cv2.resize(image, new_size)\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "# Preprocess Text file\n",
        "\n",
        "def preprocess_text(txt_pth):\n",
        "    english_chars = '[A-Za-z0-9۱۲۳۴۵۶۷۸۹۰]'\n",
        "\n",
        "    with open(txt_pth, mode='r', encoding='utf-8-sig') as f:\n",
        "        try:\n",
        "            text = f.read()\n",
        "\n",
        "            non_joiners = ['آ', 'ا', 'د', 'ڈ', 'ذ', 'ر', 'ڑ', 'ز', 'ژ', 'ں', 'و', 'ے', '\\\"', '،', '(', ')', '؟', '۔', '!', ':']\n",
        "            ligatures = []\n",
        "            ligatures_return = []\n",
        "\n",
        "            words = text.split(' ')\n",
        "\n",
        "            for word in words:\n",
        "                ligature = ''\n",
        "                for char in word:\n",
        "                    if char not in non_joiners:\n",
        "                        ligature += char\n",
        "                    else:\n",
        "                        ligature += char\n",
        "                        ligatures.append(ligature)\n",
        "                        ligatures_return.append(ligature)\n",
        "                        ligature = ''\n",
        "                if ligature!= '':\n",
        "                    ligatures.append(ligature)\n",
        "                    ligatures_return.append(ligature)\n",
        "\n",
        "            extra_char = ['\\\"', '،', '(', ')', '؟', '۔', '!', ':', 'ء']\n",
        "\n",
        "            lig_list = []\n",
        "            for ligature in ligatures:\n",
        "                for char in ligature:\n",
        "                    result = re.findall(english_chars, char)\n",
        "                    if result:\n",
        "                        lig_list.append(char + '_isolated')\n",
        "                        ligature = ligature.replace(char, '')\n",
        "                    if char in extra_char:\n",
        "                        char_index = ligature.index(char)\n",
        "                        ligature = ligature.replace(char, '')\n",
        "                if ligature:\n",
        "                    if (len(ligature) == 1):\n",
        "                        a = ligature + '_isolated'\n",
        "                        lig_list.append(a)\n",
        "                    else:\n",
        "                        initial = ligature[0]\n",
        "                        b = initial + '_initial'\n",
        "                        lig_list.append(b)\n",
        "                        middles = ligature[1:-1]\n",
        "                        if middles:\n",
        "                            for middle in middles:\n",
        "                                c = middle + '_middle'\n",
        "                                lig_list.append(c)\n",
        "                        final = ligature[-1]\n",
        "                        d = final + '_final'\n",
        "                        lig_list.append(d)\n",
        "\n",
        "            # Load the label dictionary from the CSV file\n",
        "            with open(lt_pth, mode='r') as lt_file:\n",
        "                reader = csv.reader(lt_file)\n",
        "                label_dict = {row[0]: int(row[1]) for row in reader}\n",
        "\n",
        "            # Convert the ligatures to labels\n",
        "            labels = [label_dict.get(lig, 0) for lig in lig_list]\n",
        "\n",
        "            return labels\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"Exception occured\")\n",
        "            print(e)\n",
        "            return []\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AjyxeYs1gQJf"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "labels = []\n",
        "\n",
        "for img_pth, txt_pth in zip(img_pths,txt_pths):\n",
        "  image = preprocess_image(img_pth)\n",
        "  images.append(image)\n",
        "\n",
        "  label = preprocess_text(txt_pth)\n",
        "  labels.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1E8ebo9OqoIi",
        "outputId": "658c4adb-ce69-467f-9658-a6758962b66e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 64, 1000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "\"\"\"\n",
        "  Label Padding is not required, as CTC can handle variable length labels.\n",
        "  You need to find the vocabulary size, which will be the number of classes your model will need to predict.\n",
        "\"\"\"\n",
        "\n",
        "images = np.expand_dims(images, axis=-1)\n",
        "images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0Lvfj_HoKU5",
        "outputId": "29ec9f07-efc5-4eff-d255-f63e64a9e413"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Normalize images to have values between 0 and 1\n",
        "images = np.array(images) / 255.0\n",
        "# Pad labels to the same length with 999, as it is not in the char vocabulary.\n",
        "max_label_length = max(len(label) for label in labels)\n",
        "padded_labels = pad_sequences(labels, maxlen=max_label_length, padding='post', value=999)\n",
        "\n",
        "max_label_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "U-AsLTzeowOi"
      },
      "outputs": [],
      "source": [
        "for label in padded_labels:\n",
        "  if len(label) != 81:\n",
        "    print(len(label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFdoMTB0rQii",
        "outputId": "c3c7cf2c-4ebf-406f-d7b0-6effb3b762a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of images is : <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Type of labels is :  <class 'tensorflow.python.framework.ops.EagerTensor'>\n"
          ]
        }
      ],
      "source": [
        "# Convert image lists to TensorFlow tensors\n",
        "image_tensors = tf.convert_to_tensor(images)\n",
        "\n",
        "# use ragged tensors, as your list elements are of variable length.\n",
        "labels = tf.convert_to_tensor(padded_labels)\n",
        "\n",
        "print(\"Type of images is :\", type(image_tensors))\n",
        "print(\"Type of labels is : \",type(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10aDIDEqZXxa",
        "outputId": "b88ec164-661e-446d-d28c-a2dcf34c8f3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# number of classes should be the total number of the characters in our vocabulary\n",
        "lt_pth = \"/content/drive/MyDrive/My Documents/Pdf_Ocr/Datasets/Training_200_set/labels/lt_char.csv\"\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv(lt_pth)\n",
        "num_classes = df.shape[0] + 1\n",
        "num_classes # it is actually the total number of the characters we need to predict."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "id": "IpZNcwsihgcL"
      },
      "outputs": [],
      "source": [
        "# Number of classes (including the blank label for CTC)\n",
        "num_classes = num_classes + 1  # Update this based on the actual number of unique labels + 1 for the blank label\n",
        "\n",
        "# Convert labels to a numpy array\n",
        "padded_labels = np.array(padded_labels)\n",
        "\n",
        "# Input lengths (all sequences have the same length in this case)\n",
        "input_lengths = np.ones((len(image_tensors), 1)) * (image_tensors.shape[2] // 2)\n",
        "\n",
        "# Label lengths (actual lengths of the labels)\n",
        "label_lengths = np.array([len(label) for label in labels]).reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xiMxNSLmjGu9"
      },
      "outputs": [],
      "source": [
        "# Create the dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((image_tensors, padded_labels))\n",
        "\n",
        "# Shuffle the entire dataset\n",
        "dataset = dataset.shuffle(buffer_size=len(image_tensors), seed=42)\n",
        "\n",
        "# Define the split ratio\n",
        "validation_split = 0.2\n",
        "num_samples = len(image_tensors)\n",
        "num_val_samples = int(validation_split * num_samples)\n",
        "num_train_samples = num_samples - num_val_samples\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_dataset = dataset.take(num_train_samples)\n",
        "val_dataset = dataset.skip(num_train_samples)\n",
        "\n",
        "# Batch the datasets\n",
        "BATCH_SIZE = 5\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "collapsed": true,
        "id": "AgFrLItSgHjl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LSTM, Bidirectional, Reshape\n",
        "from keras.optimizers import Adam\n",
        "import keras.backend as K\n",
        "from keras.utils import pad_sequences\n",
        "from keras.layers import Input, Lambda\n",
        "from keras.models import Model\n",
        "import nltk\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "# CNN Layers\n",
        "# CNN Layer 1\n",
        "model.add(Conv2D(filters=32, kernel_size=(5, 5), strides=(1, 1), padding='SAME', activation='relu', input_shape=(64, 1000, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='SAME'))\n",
        "\n",
        "# CNN Layer 2\n",
        "model.add(Conv2D(filters=64, kernel_size=(5, 5), strides=(1, 2), padding='SAME', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding='SAME'))\n",
        "\n",
        "# CNN Layer 3\n",
        "model.add(Conv2D(filters=128, kernel_size=(5, 5), strides=(1, 2), padding='SAME', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding='SAME'))\n",
        "\n",
        "# CNN Layer 4\n",
        "model.add(Conv2D(filters=128, kernel_size=(5, 5), strides=(1, 2), padding='SAME', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding='SAME'))\n",
        "\n",
        "# CNN Layer 5\n",
        "model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 2), padding='SAME', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding='SAME'))\n",
        "\n",
        "# CNN Layer 6\n",
        "model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 2), padding='SAME', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding='SAME'))\n",
        "\n",
        "# CNN Layer 7\n",
        "model.add(Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), padding='SAME', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(1, 1), strides=(1, 1), padding='SAME'))\n",
        "\n",
        "# Flatten Layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# Calculate the output shape after the CNN layers\n",
        "# Assuming input shape is (64, 1000, 1), the output shape after Flatten will be (16, 1024)\n",
        "# Thus, we need to reshape it to (81, something) for LSTM layers\n",
        "\n",
        "# Adjust Reshape Layer\n",
        "model.add(Reshape((128, 128)))  # Adjust 'something' based on the output shape after Flatten and before Reshape\n",
        "\n",
        "# Bidirectional LSTM Layers\n",
        "# Bidirectional LSTM Layer 1\n",
        "model.add(Bidirectional(LSTM(units=512, return_sequences=True)))\n",
        "\n",
        "# Bidirectional LSTM Layer 2\n",
        "model.add(Bidirectional(LSTM(units=512, return_sequences=True)))\n",
        "\n",
        "# Dropout Layer\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Functions\n",
        "\n",
        "def CTCLoss(y_true, y_pred):\n",
        "    # Compute the training-time loss value\n",
        "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    # print(\"Lengths are : \",type(input_length),type(label_length))\n",
        "    # print(\"Lengths are : \",input_length,label_length)\n",
        "    loss = K.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "QvMcEVnWmSPB"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NQBs0JLvpSjy"
      },
      "outputs": [],
      "source": [
        "# Optimizer\n",
        "opt = Adam(learning_rate=0.001)\n",
        "model.compile(loss = CTCLoss, optimizer= opt)\n",
        "\n",
        "# Fit the model using the training and validation datasets\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=10,\n",
        "    validation_data=val_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWHtvEMMpfaA",
        "outputId": "ceda86b9-ce25-406f-88c6-49db335da19f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save('/content/drive/MyDrive/My Documents/Pdf_Ocr/first_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "lX-RxWnVPsM3"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess your image\n",
        "img_pth = \"/content/drive/MyDrive/My Documents/Pdf_Ocr/Datasets/Training_200_set/images/Al Jihad Fil Islam (Volume 02) SwaneUmri Hazrat Uma100_Line7.jpg\"\n",
        "img = cv2.imread(img_pth)\n",
        "\n",
        "# Resize the image to match your model's input shape (1000, 64, 1)\n",
        "new_size = (1000, 64)  # width, height\n",
        "img = cv2.resize(img, new_size)\n",
        "\n",
        "# Convert to grayscale\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Normalize the image to have values between 0 and 1\n",
        "img_normalized = img_gray / 255.0\n",
        "\n",
        "# Expand dimensions to make it a batch of 1 (if necessary)\n",
        "img_input = np.expand_dims(img_normalized, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1ZA4U7zQTsT",
        "outputId": "86c46a60-40c1-4d72-9051-fbff992ed1c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load your trained model\n",
        "model_path = \"/content/drive/MyDrive/My Documents/Pdf_Ocr/first_model.h5\"\n",
        "model = load_model(model_path, custom_objects={'CTCLoss': CTCLoss})\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(img_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fjQ609v0_nd",
        "outputId": "eb5f9f83-7702-4315-ac82-16169da5061c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 459ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6JzFbY1RGFA",
        "outputId": "a1bc500d-5655-4b8b-a2da-a57ab06ff920"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1.1519050e-02, 2.4325051e-04, 3.1199835e-03, ...,\n",
              "         8.3262266e-06, 1.0694757e-05, 7.6095611e-02],\n",
              "        [6.6412009e-02, 6.4807228e-04, 2.2023341e-04, ...,\n",
              "         6.0783523e-06, 8.5689480e-06, 5.2516967e-01],\n",
              "        [5.9029865e-03, 1.0208150e-03, 9.7988464e-05, ...,\n",
              "         8.2924538e-07, 1.9935997e-06, 6.9850719e-01],\n",
              "        ...,\n",
              "        [1.5212782e-02, 5.9366360e-04, 2.8618608e-04, ...,\n",
              "         2.2555716e-06, 2.4901246e-06, 7.1094358e-01],\n",
              "        [2.5523128e-03, 1.0333974e-03, 1.4288729e-04, ...,\n",
              "         1.0565723e-06, 1.9818876e-06, 6.8200594e-01],\n",
              "        [1.9799829e-02, 4.2850129e-02, 3.0595325e-03, ...,\n",
              "         1.3863455e-05, 1.6370152e-05, 8.2115822e-02]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T2JgIiBRG07",
        "outputId": "09a2ad87-a94e-40f5-ec31-b31411e6a6a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "201"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "len(predictions[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atKBu2hX0Rbn",
        "outputId": "d5f2216e-f973-4288-f56c-c5dfc764f859"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 128, 201)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_reshaped = predictions.reshape((128, 201))"
      ],
      "metadata": {
        "id": "xsptqMyS0lbl"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf5_8-YxRKqx",
        "outputId": "4715f31d-15fd-463f-f8b7-e8323ba52b70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16 27 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1]\n"
          ]
        }
      ],
      "source": [
        "def ctc_decode(predictions):\n",
        "    # Assume predictions shape is (1, T, C), where T is time steps and C is classes\n",
        "    pred_shape = predictions.shape\n",
        "    pred_labels = K.ctc_decode(predictions, input_length=np.ones(pred_shape[0]) * pred_shape[1])[0][0]\n",
        "\n",
        "    # Convert sparse tensor to string\n",
        "    decoded_text = K.get_value(pred_labels[0])\n",
        "\n",
        "    return decoded_text\n",
        "\n",
        "# Assuming predictions is your model output for the single image\n",
        "decoded_text = ctc_decode(predictions)\n",
        "print(decoded_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gt_pth = \"/content/drive/MyDrive/My Documents/Pdf_Ocr/Datasets/Training_200_set/texts/Al Jihad Fil Islam (Volume 02) SwaneUmri Hazrat Uma100_Line7.txt\"\n",
        "\n",
        "with open(gt_pth, 'r') as file:\n",
        "  content = file.readlines()\n",
        "  print(content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgAQ6qCt5Ggs",
        "outputId": "44a3a597-5218-43ce-8d0c-c41733d2bfb0"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['’’سب لوگوں کو معلوم ہے کہ میں سب سے زیادہ مستحق ہوں جس ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label = preprocess_text(gt_pth)\n",
        "print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ih2NZlD5a4j",
        "outputId": "7e1c08ed-9a12-4ad6-e875-18b8cc38dca6"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 72, 85, 64, 1, 31, 1, 58, 26, 1, 7, 75, 49, 1, 50, 47, 27, 26, 45, 7, 8, 9, 21, 85, 21, 27, 83, 20, 14, 12, 46, 7, 72, 22, 69, 79, 47, 1, 58, 10, 38]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aht83N436Y39",
        "outputId": "8932c128-b334-4ab0-99ed-3352dfd740c4"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Levenshtein\n",
            "  Downloading Levenshtein-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=3.8.0 (from Levenshtein)\n",
            "  Downloading rapidfuzz-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n",
            "Successfully installed Levenshtein-0.25.1 rapidfuzz-3.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Levenshtein import distance\n",
        "\n",
        "def character_error_rate(y_true, y_pred):\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # Filter out blanks (-1) from both true and predicted sequences\n",
        "    true_filtered = [char for char in y_true if char != -1]\n",
        "    pred_filtered = [char for char in y_pred if char != -1]\n",
        "\n",
        "    # Calculate Levenshtein distance between true and predicted sequences\n",
        "    dist = distance(''.join(map(str, true_filtered)), ''.join(map(str, pred_filtered)))\n",
        "\n",
        "    # Calculate Character Error Rate\n",
        "    cer = dist / len(true_filtered) if len(true_filtered) > 0 else 0.0\n",
        "\n",
        "    return cer\n",
        "\n",
        "loss = character_error_rate(label, decoded_text)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xrlUyA85rzq",
        "outputId": "ecc85513-da77-43bd-d9a1-007229753c47"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.619047619047619\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGoYkgP3scySm4XneU80XJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}