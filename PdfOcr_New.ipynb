{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRHW9Gv7r8BD3y4Mt5UkxC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArooshKics/PdfOcrCode/blob/master/PdfOcr_New.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "8rEbp_aeKbGX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcf8b1e6-e681-4722-8ec7-fec7b454fcc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive is already mounted.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import csv\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, Conv2D, MaxPooling2D, BatchNormalization, Activation, Reshape, Dense, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# Check if Google Drive is mounted\n",
        "if not os.path.exists('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "else:\n",
        "    print(\"Google Drive is already mounted.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths of images and text directories\n",
        "images_dir = '/content/drive/MyDrive/My Documents/Pdf_Ocr/Datasets/Training_200_set/images'\n",
        "texts_dir = '/content/drive/MyDrive/My Documents/Pdf_Ocr/Datasets/Training_200_set/texts'\n",
        "lt_pth = '/content/drive/MyDrive/My Documents/Pdf_Ocr/Datasets/Training_200_set/labels/lt_char.csv'"
      ],
      "metadata": {
        "id": "3P5aI2JvKyjK"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Images and their corresponding text.\n",
        "\n",
        "img_pths= []\n",
        "txt_pths = []\n",
        "\n",
        "for img_name in os.listdir(images_dir):\n",
        "  img_pth = os.path.join(images_dir, img_name)\n",
        "  txt_pth = os.path.join(texts_dir, img_name[:-4]+\".txt\")\n",
        "\n",
        "  if os.path.exists(img_pth) and os.path.exists(txt_pth):\n",
        "    img_pths.append(img_pth)\n",
        "    txt_pths.append(txt_pth)\n"
      ],
      "metadata": {
        "id": "6yzzARjPOPx8"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(img_pths), len(txt_pths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujCXdQvGPjA5",
        "outputId": "6110bcbd-73d7-44c2-b124-6b9897dd074b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import re\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    # # Read image\n",
        "    # image = tf.io.read_file(image_path)\n",
        "    # # Decode image\n",
        "    # image = tf.io.decode_image(image, channels=3)  # Assuming RGB images\n",
        "    # # Resize image if needed\n",
        "    # # image = tf.image.resize(image, [new_height, new_width])\n",
        "\n",
        "    image = cv2.imread(image_path)\n",
        "    new_size = (1000, 64) # width, height, channel\n",
        "    image = cv2.resize(image, new_size)\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "# Preprocess Text file\n",
        "\n",
        "def preprocess_text(txt_pth):\n",
        "    english_chars = '[A-Za-z0-9۱۲۳۴۵۶۷۸۹۰]'\n",
        "\n",
        "    with open(txt_pth, mode='r', encoding='utf-8-sig') as f:\n",
        "        try:\n",
        "            text = f.read()\n",
        "\n",
        "            non_joiners = ['آ', 'ا', 'د', 'ڈ', 'ذ', 'ر', 'ڑ', 'ز', 'ژ', 'ں', 'و', 'ے', '\\\"', '،', '(', ')', '؟', '۔', '!', ':']\n",
        "            ligatures = []\n",
        "            ligatures_return = []\n",
        "\n",
        "            words = text.split(' ')\n",
        "\n",
        "            for word in words:\n",
        "                ligature = ''\n",
        "                for char in word:\n",
        "                    if char not in non_joiners:\n",
        "                        ligature += char\n",
        "                    else:\n",
        "                        ligature += char\n",
        "                        ligatures.append(ligature)\n",
        "                        ligatures_return.append(ligature)\n",
        "                        ligature = ''\n",
        "                if ligature!= '':\n",
        "                    ligatures.append(ligature)\n",
        "                    ligatures_return.append(ligature)\n",
        "\n",
        "            extra_char = ['\\\"', '،', '(', ')', '؟', '۔', '!', ':', 'ء']\n",
        "\n",
        "            lig_list = []\n",
        "            for ligature in ligatures:\n",
        "                for char in ligature:\n",
        "                    result = re.findall(english_chars, char)\n",
        "                    if result:\n",
        "                        lig_list.append(char + '_isolated')\n",
        "                        ligature = ligature.replace(char, '')\n",
        "                    if char in extra_char:\n",
        "                        char_index = ligature.index(char)\n",
        "                        ligature = ligature.replace(char, '')\n",
        "                if ligature:\n",
        "                    if (len(ligature) == 1):\n",
        "                        a = ligature + '_isolated'\n",
        "                        lig_list.append(a)\n",
        "                    else:\n",
        "                        initial = ligature[0]\n",
        "                        b = initial + '_initial'\n",
        "                        lig_list.append(b)\n",
        "                        middles = ligature[1:-1]\n",
        "                        if middles:\n",
        "                            for middle in middles:\n",
        "                                c = middle + '_middle'\n",
        "                                lig_list.append(c)\n",
        "                        final = ligature[-1]\n",
        "                        d = final + '_final'\n",
        "                        lig_list.append(d)\n",
        "\n",
        "            # Load the label dictionary from the CSV file\n",
        "            with open(lt_pth, mode='r') as lt_file:\n",
        "                reader = csv.reader(lt_file)\n",
        "                label_dict = {row[0]: int(row[1]) for row in reader}\n",
        "\n",
        "            # Convert the ligatures to labels\n",
        "            labels = [label_dict.get(lig, 0) for lig in lig_list]\n",
        "\n",
        "            return labels\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"Exception occured\")\n",
        "            print(e)\n",
        "            return []\n",
        "\n"
      ],
      "metadata": {
        "id": "4K23QqxhMgAR"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "labels = []\n",
        "\n",
        "for img_pth, txt_pth in zip(img_pths,txt_pths):\n",
        "  image = preprocess_image(img_pth)\n",
        "  images.append(image)\n",
        "\n",
        "  label = preprocess_text(txt_pth)\n",
        "  labels.append(label)"
      ],
      "metadata": {
        "id": "AjyxeYs1gQJf"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  Label Padding is not required, as CTC can handle variable length labels.\n",
        "  You need to find the vocabulary size, which will be the number of classes your model will need to predict.\n",
        "\"\"\"\n",
        "\n",
        "images = np.expand_dims(images, axis=-1)\n",
        "images.shape"
      ],
      "metadata": {
        "id": "1E8ebo9OqoIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b565f12f-fd84-4615-8e9c-77ebaf81c1c5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 64, 1000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Normalize images to have values between 0 and 1\n",
        "images = np.array(images) / 255.0\n",
        "# Pad labels to the same length with -1\n",
        "max_label_length = max(len(label) for label in labels)\n",
        "padded_labels = pad_sequences(labels, maxlen=max_label_length, padding='post', value=999)  # Use -1 as padding value or any value not in your labels vocabulary\n",
        "\n",
        "max_label_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0Lvfj_HoKU5",
        "outputId": "18ffbb8b-2b5a-4e65-95b1-212ac6f79cc6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for label in padded_labels:\n",
        "  if len(label) != 81:\n",
        "    print(len(label))"
      ],
      "metadata": {
        "id": "U-AsLTzeowOi"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert image lists to TensorFlow tensors\n",
        "image_tensors = tf.convert_to_tensor(images)\n",
        "\n",
        "# use ragged tensors, as your list elements are of variable length.\n",
        "labels = tf.convert_to_tensor(padded_labels)\n",
        "\n",
        "print(\"Type of images is :\", type(image_tensors))\n",
        "print(\"Type of labels is : \",type(labels))"
      ],
      "metadata": {
        "id": "sFdoMTB0rQii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbff0831-0680-48b0-bc98-2868db5e51c1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of images is : <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Type of labels is :  <class 'tensorflow.python.framework.ops.EagerTensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of classes should be the total number of the characters in our vocabulary\n",
        "lt_pth = \"/content/drive/MyDrive/My Documents/Pdf_Ocr/Datasets/Training_200_set/labels/lt_char.csv\"\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv(lt_pth)\n",
        "num_classes = df.shape[0] + 1\n",
        "num_classes # it is actually the total number of the characters we need to predict."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10aDIDEqZXxa",
        "outputId": "2b565a69-11ed-416c-b627-5036327009ff"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of classes (including the blank label for CTC)\n",
        "num_classes = num_classes + 1  # Update this based on the actual number of unique labels + 1 for the blank label\n",
        "\n",
        "# Convert labels to a numpy array\n",
        "padded_labels = np.array(padded_labels)\n",
        "\n",
        "# Input lengths (all sequences have the same length in this case)\n",
        "input_lengths = np.ones((len(image_tensors), 1)) * (image_tensors.shape[2] // 2)\n",
        "\n",
        "# Label lengths (actual lengths of the labels)\n",
        "label_lengths = np.array([len(label) for label in labels]).reshape(-1, 1)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IpZNcwsihgcL"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((image_tensors, padded_labels))\n",
        "\n",
        "# Shuffle and batch the dataset\n",
        "BATCH_SIZE = 5\n",
        "dataset = dataset.shuffle(buffer_size=len(image_tensors)).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "xiMxNSLmjGu9"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LSTM, Bidirectional, Reshape\n",
        "from keras.optimizers import Adam\n",
        "import keras.backend as K\n",
        "from keras.utils import pad_sequences\n",
        "from keras.layers import Input, Lambda\n",
        "from keras.models import Model\n",
        "\n",
        "def CTCLoss(y_true, y_pred):\n",
        "    # Compute the training-time loss value\n",
        "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    # print(\"Lengths are : \",type(input_length),type(label_length))\n",
        "    # print(\"Lengths are : \",input_length,label_length)\n",
        "    loss = K.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "    return loss\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "# CNN Layers\n",
        "# CNN Layer 1\n",
        "model.add(Conv2D(filters=32, kernel_size=(5, 5), strides=(1, 1), padding='SAME', activation='relu', input_shape=(64, 1000, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='SAME'))\n",
        "\n",
        "# CNN Layer 2\n",
        "model.add(Conv2D(filters=64, kernel_size=(5, 5), strides=(1, 2), padding='SAME', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding='SAME'))\n",
        "\n",
        "# CNN Layer 3\n",
        "model.add(Conv2D(filters=128, kernel_size=(5, 5), strides=(1, 2), padding='SAME', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding='SAME'))\n",
        "\n",
        "# CNN Layer 4\n",
        "model.add(Conv2D(filters=128, kernel_size=(5, 5), strides=(1, 2), padding='SAME', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding='SAME'))\n",
        "\n",
        "# CNN Layer 5\n",
        "model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 2), padding='SAME', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding='SAME'))\n",
        "\n",
        "# CNN Layer 6\n",
        "model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 2), padding='SAME', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding='SAME'))\n",
        "\n",
        "# CNN Layer 7\n",
        "model.add(Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), padding='SAME', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(1, 1), strides=(1, 1), padding='SAME'))\n",
        "\n",
        "# Flatten Layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# Calculate the output shape after the CNN layers\n",
        "# Assuming input shape is (64, 1000, 1), the output shape after Flatten will be (16, 1024)\n",
        "# Thus, we need to reshape it to (81, something) for LSTM layers\n",
        "\n",
        "# Adjust Reshape Layer\n",
        "model.add(Reshape((128, 128)))  # Adjust 'something' based on the output shape after Flatten and before Reshape\n",
        "\n",
        "# Bidirectional LSTM Layers\n",
        "# Bidirectional LSTM Layer 1\n",
        "model.add(Bidirectional(LSTM(units=512, return_sequences=True)))\n",
        "\n",
        "# Bidirectional LSTM Layer 2\n",
        "model.add(Bidirectional(LSTM(units=512, return_sequences=True)))\n",
        "\n",
        "# Dropout Layer\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "AgFrLItSgHjl",
        "collapsed": true
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer\n",
        "opt = Adam(learning_rate=0.001)\n",
        "model.compile(loss = CTCLoss, optimizer= opt)\n",
        "\n",
        "history = model.fit(dataset, epochs = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NQBs0JLvpSjy",
        "outputId": "6738bf95-e739-471c-dc03-7a8451455ef0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "40/40 [==============================] - 509s 12s/step - loss: 288.5347\n",
            "Epoch 2/10\n",
            "40/40 [==============================] - 513s 13s/step - loss: 253.3310\n",
            "Epoch 3/10\n",
            "40/40 [==============================] - 489s 12s/step - loss: 253.7258\n",
            "Epoch 4/10\n",
            "40/40 [==============================] - 476s 12s/step - loss: 252.3386\n",
            "Epoch 5/10\n",
            "40/40 [==============================] - 490s 12s/step - loss: 251.5813\n",
            "Epoch 6/10\n",
            "40/40 [==============================] - 513s 13s/step - loss: 250.1203\n",
            "Epoch 7/10\n",
            "40/40 [==============================] - 487s 12s/step - loss: 243.2217\n",
            "Epoch 8/10\n",
            "40/40 [==============================] - 476s 12s/step - loss: 239.0557\n",
            "Epoch 9/10\n",
            "40/40 [==============================] - 471s 12s/step - loss: 237.8009\n",
            "Epoch 10/10\n",
            "40/40 [==============================] - 473s 12s/step - loss: 236.5743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/My Documents/Pdf_Ocr/first_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWHtvEMMpfaA",
        "outputId": "ceda86b9-ce25-406f-88c6-49db335da19f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess your image\n",
        "img_pth = \"/content/drive/MyDrive/My Documents/Pdf_Ocr/Datasets/Training_200_set/images/Al Jihad Fil Islam (Volume 02) SwaneUmri Hazrat Uma100_Line7.jpg\"\n",
        "img = cv2.imread(img_pth)\n",
        "\n",
        "# Resize the image to match your model's input shape (1000, 64, 1)\n",
        "new_size = (1000, 64)  # width, height\n",
        "img = cv2.resize(img, new_size)\n",
        "\n",
        "# Convert to grayscale\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Normalize the image to have values between 0 and 1\n",
        "img_normalized = img_gray / 255.0\n",
        "\n",
        "# Expand dimensions to make it a batch of 1 (if necessary)\n",
        "img_input = np.expand_dims(img_normalized, axis=0)"
      ],
      "metadata": {
        "id": "lX-RxWnVPsM3"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load your trained model\n",
        "model_path = \"/content/drive/MyDrive/My Documents/Pdf_Ocr/first_model.h5\"\n",
        "model = load_model(model_path, custom_objects={'CTCLoss': CTCLoss})\n",
        "\n",
        "predictions = model.predict(img_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1ZA4U7zQTsT",
        "outputId": "bd190cf6-513f-428e-f1f6-809853bfc7c2"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6JzFbY1RGFA",
        "outputId": "5fb0d997-aace-4cc0-eb43-af6f60cb3ec0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1.1519050e-02, 2.4325051e-04, 3.1199835e-03, ...,\n",
              "         8.3262266e-06, 1.0694757e-05, 7.6095611e-02],\n",
              "        [6.6412009e-02, 6.4807228e-04, 2.2023341e-04, ...,\n",
              "         6.0783523e-06, 8.5689480e-06, 5.2516967e-01],\n",
              "        [5.9029865e-03, 1.0208150e-03, 9.7988464e-05, ...,\n",
              "         8.2924538e-07, 1.9935997e-06, 6.9850719e-01],\n",
              "        ...,\n",
              "        [1.5212782e-02, 5.9366360e-04, 2.8618608e-04, ...,\n",
              "         2.2555716e-06, 2.4901246e-06, 7.1094358e-01],\n",
              "        [2.5523128e-03, 1.0333974e-03, 1.4288729e-04, ...,\n",
              "         1.0565723e-06, 1.9818876e-06, 6.8200594e-01],\n",
              "        [1.9799829e-02, 4.2850129e-02, 3.0595325e-03, ...,\n",
              "         1.3863455e-05, 1.6370152e-05, 8.2115822e-02]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(predictions[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T2JgIiBRG07",
        "outputId": "8486720c-ab78-48ef-c5c2-b6e5e271f49d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "201"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ctc_decode(predictions):\n",
        "    # Assume predictions shape is (1, T, C), where T is time steps and C is classes\n",
        "    pred_shape = predictions.shape\n",
        "    pred_labels = K.ctc_decode(predictions, input_length=np.ones(pred_shape[0]) * pred_shape[1])[0][0]\n",
        "\n",
        "    # Convert sparse tensor to string\n",
        "    decoded_text = K.get_value(pred_labels[0])\n",
        "\n",
        "    return decoded_text\n",
        "\n",
        "# Assuming predictions is your model output for the single image\n",
        "decoded_text = ctc_decode(predictions)\n",
        "print(decoded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf5_8-YxRKqx",
        "outputId": "23cf5b29-f306-4fde-95eb-8a066b11673e"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16 27 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1]\n"
          ]
        }
      ]
    }
  ]
}